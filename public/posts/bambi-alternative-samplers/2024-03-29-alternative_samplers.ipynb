{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: 'Alternative Samplers to NUTS in Bambi'\n",
    "date: 2024-03-29\n",
    "author: 'Gabriel Stechschulte'\n",
    "draft: false\n",
    "categories: ['probabilistic-programming']\n",
    "---\n",
    "\n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative sampling backends\n",
    "\n",
    "This blog post is a copy of the alternative samplers documentation I wrote for [Bambi](https://bambinos.github.io/bambi/). The original post can be found [here](https://bambinos.github.io/bambi/notebooks/).\n",
    "\n",
    "In Bambi, the sampler used is automatically selected given the type of variables used in the model. For inference, Bambi supports both MCMC and variational inference. By default, Bambi uses PyMC's implementation of the adaptive Hamiltonian Monte Carlo (HMC) algorithm for sampling. Also known as the No-U-Turn Sampler (NUTS). This sampler is a good choice for many models. However, it is not the only sampling method, nor is PyMC the only library implementing NUTS. \n",
    "\n",
    "To this extent, Bambi supports multiple backends for MCMC sampling such as NumPyro and Blackjax. This notebook will cover how to use such alternatives in Bambi.\n",
    "\n",
    "_Note_: Bambi utilizes [bayeux](https://github.com/jax-ml/bayeux) to access a variety of sampling backends. Thus, you will need to install the optional dependencies in the Bambi [pyproject.toml](https://github.com/bambinos/bambi/blob/main/pyproject.toml) file to use these backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import bayeux as bx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayeux\n",
    "\n",
    "Bambi leverages `bayeux` to access different sampling backends. In short, `bayeux` lets you write a probabilistic model in JAX and immediately have access to state-of-the-art inference methods. \n",
    "\n",
    "Since the underlying Bambi model is a PyMC model, this PyMC model can be \"given\" to `bayeux`. Then, we can choose from a variety of MCMC methods to perform inference. \n",
    "\n",
    "To demonstrate the available backends, we will fist simulate data and build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "num_features = 1\n",
    "noise_std = 1.0\n",
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "coefficients = np.random.randn(num_features)\n",
    "X = np.random.randn(num_samples, num_features)\n",
    "error = np.random.normal(scale=noise_std, size=num_samples)\n",
    "y = X @ coefficients + error\n",
    "\n",
    "data = pd.DataFrame({\"y\": y, \"x\": X.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bmb.Model(\"y ~ x\", data)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `bmb.inference_methods.names` that returns a nested dictionary of the backends and list of inference methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pymc': {'mcmc': ['mcmc'], 'vi': ['vi']},\n",
       " 'bayeux': {'mcmc': ['tfp_hmc',\n",
       "   'tfp_nuts',\n",
       "   'tfp_snaper_hmc',\n",
       "   'blackjax_hmc',\n",
       "   'blackjax_chees_hmc',\n",
       "   'blackjax_meads_hmc',\n",
       "   'blackjax_nuts',\n",
       "   'blackjax_hmc_pathfinder',\n",
       "   'blackjax_nuts_pathfinder',\n",
       "   'flowmc_rqspline_hmc',\n",
       "   'flowmc_rqspline_mala',\n",
       "   'flowmc_realnvp_hmc',\n",
       "   'flowmc_realnvp_mala',\n",
       "   'numpyro_hmc',\n",
       "   'numpyro_nuts']}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = bmb.inference_methods.names\n",
    "methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the PyMC backend, we have access to their implementation of the NUTS sampler and mean-field variational inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcmc': ['mcmc'], 'vi': ['vi']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods[\"pymc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bayeux` lets us have access to Tensorflow probability, Blackjax, FlowMC, and NumPyro backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcmc': ['tfp_hmc',\n",
       "  'tfp_nuts',\n",
       "  'tfp_snaper_hmc',\n",
       "  'blackjax_hmc',\n",
       "  'blackjax_chees_hmc',\n",
       "  'blackjax_meads_hmc',\n",
       "  'blackjax_nuts',\n",
       "  'blackjax_hmc_pathfinder',\n",
       "  'blackjax_nuts_pathfinder',\n",
       "  'flowmc_rqspline_hmc',\n",
       "  'flowmc_rqspline_mala',\n",
       "  'flowmc_realnvp_hmc',\n",
       "  'flowmc_realnvp_mala',\n",
       "  'numpyro_hmc',\n",
       "  'numpyro_nuts']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods[\"bayeux\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the MCMC and VI keys in the dictionary are the names of the argument you would pass to `inference_method` in `model.fit`. This is shown in the section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying an `inference_method`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Bambi uses the PyMC NUTS implementation. To use a different backend, pass the name of the `bayeux` MCMC method to the `inference_method` parameter of the `fit` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackjax_nuts_idata = model.fit(inference_method=\"blackjax_nuts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different backends have different naming conventions for the parameters specific to that MCMC method. Thus, to specify backend-specific parameters, pass your own `kwargs` to the `fit` method.\n",
    "\n",
    "The following can be performend to identify the kwargs specific to each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<function blackjax.adaptation.window_adaptation.window_adaptation(algorithm: Union[blackjax.mcmc.hmc.hmc, blackjax.mcmc.nuts.nuts], logdensity_fn: Callable, is_mass_matrix_diagonal: bool = True, initial_step_size: float = 1.0, target_acceptance_rate: float = 0.8, progress_bar: bool = False, **extra_parameters) -> blackjax.base.AdaptationAlgorithm>: {'logdensity_fn': <function bayeux._src.shared.constrain.<locals>.wrap_log_density.<locals>.wrapped(args)>,\n",
       "  'is_mass_matrix_diagonal': True,\n",
       "  'initial_step_size': 1.0,\n",
       "  'target_acceptance_rate': 0.8,\n",
       "  'progress_bar': False,\n",
       "  'algorithm': blackjax.mcmc.nuts.nuts},\n",
       " 'adapt.run': {'num_steps': 500},\n",
       " blackjax.mcmc.nuts.nuts: {'max_num_doublings': 10,\n",
       "  'divergence_threshold': 1000,\n",
       "  'integrator': <function blackjax.mcmc.integrators.generate_euclidean_integrator.<locals>.euclidean_integrator(logdensity_fn: Callable, kinetic_energy_fn: blackjax.mcmc.metrics.KineticEnergy) -> Callable[[blackjax.mcmc.integrators.IntegratorState, float], blackjax.mcmc.integrators.IntegratorState]>,\n",
       "  'logdensity_fn': <function bayeux._src.shared.constrain.<locals>.wrap_log_density.<locals>.wrapped(args)>,\n",
       "  'step_size': 0.5},\n",
       " 'extra_parameters': {'chain_method': 'vectorized',\n",
       "  'num_chains': 8,\n",
       "  'num_draws': 500,\n",
       "  'num_adapt_draws': 500,\n",
       "  'return_pytree': False}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmb.inference_methods.get_kwargs(\"blackjax_nuts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can identify the kwargs we would like to change and pass to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"adapt.run\": {\"num_steps\": 500},\n",
    "        \"num_chains\": 4,\n",
    "        \"num_draws\": 250,\n",
    "        \"num_adapt_draws\": 250\n",
    "}\n",
    "\n",
    "blackjax_nuts_idata = model.fit(inference_method=\"blackjax_nuts\", **kwargs)\n",
    "blackjax_nuts_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_nuts_idata = model.fit(inference_method=\"tfp_nuts\")\n",
    "tfp_nuts_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro_nuts_idata = model.fit(inference_method=\"numpyro_nuts\")\n",
    "numpyro_nuts_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flowMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowmc_idata = model.fit(inference_method=\"flowmc_realnvp_hmc\")\n",
    "flowmc_idata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler comparisons\n",
    "\n",
    "With ArviZ, we can compare the inference result summaries of the samplers. _Note:_ We can't use `az.compare` as not each inference data object returns the pointwise log-probabilities. Thus, an error would be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>694.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>970.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_sigma</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.827</td>\n",
       "      <td>1.072</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept  0.023  0.097  -0.141    0.209      0.004    0.003     694.0   \n",
       "x          0.356  0.111   0.162    0.571      0.004    0.003     970.0   \n",
       "y_sigma    0.950  0.069   0.827    1.072      0.002    0.001    1418.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "Intercept     508.0   1.00  \n",
       "x             675.0   1.00  \n",
       "y_sigma       842.0   1.01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(blackjax_nuts_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6785.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.360</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6988.0</td>\n",
       "      <td>5116.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_sigma</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.081</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7476.0</td>\n",
       "      <td>5971.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept  0.023  0.097  -0.157    0.205      0.001    0.001    6785.0   \n",
       "x          0.360  0.105   0.169    0.563      0.001    0.001    6988.0   \n",
       "y_sigma    0.946  0.067   0.831    1.081      0.001    0.001    7476.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "Intercept    5740.0    1.0  \n",
       "x            5116.0    1.0  \n",
       "y_sigma      5971.0    1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tfp_nuts_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6851.0</td>\n",
       "      <td>5614.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.362</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>9241.0</td>\n",
       "      <td>6340.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_sigma</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7247.0</td>\n",
       "      <td>5711.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept  0.024  0.095  -0.162    0.195      0.001    0.001    6851.0   \n",
       "x          0.362  0.104   0.176    0.557      0.001    0.001    9241.0   \n",
       "y_sigma    0.946  0.068   0.826    1.079      0.001    0.001    7247.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "Intercept    5614.0    1.0  \n",
       "x            6340.0    1.0  \n",
       "y_sigma      5711.0    1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(numpyro_nuts_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>758.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>4525.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_sigma</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5536.0</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept  0.015  0.100  -0.186    0.190      0.004    0.003     758.0   \n",
       "x          0.361  0.105   0.174    0.565      0.001    0.001    5084.0   \n",
       "y_sigma    0.951  0.070   0.823    1.079      0.001    0.001    5536.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "Intercept    1233.0   1.02  \n",
       "x            4525.0   1.00  \n",
       "y_sigma      5080.0   1.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(flowmc_idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Thanks to `bayeux`, we can use three different sampling backends and 10+ alternative MCMC methods in Bambi. Using these methods is as simple as passing the inference name to the `inference_method` of the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Sat Apr 13 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.2\n",
      "IPython version      : 8.20.0\n",
      "\n",
      "bambi : 0.13.1.dev25+g1e7f677e.d20240413\n",
      "pandas: 2.2.1\n",
      "numpy : 1.26.4\n",
      "bayeux: 0.1.10\n",
      "arviz : 0.18.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayeux_bambi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
