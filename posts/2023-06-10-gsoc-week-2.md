---
title: "Google Summer of Code - Update 1"
date: "2023-06-10"
categories:
  - open-source
  - python
  - bayesian-statistics
---

## Introduction

I have been selected as a contributor under the organization [NumFOCUS](https://numfocus.org) for the Google Summer of Code 2023 program. I will be working on _developing better tools to interpret complex Bambi regression models_. More details about the project can be found [here](https://summerofcode.withgoogle.com/projects/#6187085698856448). This blog post will be a summary of the community bonding period and the first two weeks of the program.

Timeline of events:

* Community Bonding Period (May 4th - 28th)
* Week 1 (May 29th - June 4th)
* Week 2 (June 5th - June 11th)

## Community Bonding Period

The community bonding period is a time for students to get to know their mentors and organizations, and to change / finalize project details. I have been in contact with my mentors Tom√°s Capretto and Osvaldo Martin via Slack and GitHub. A goal of mine throughout the community bonding period was not only to get to know my mentors, but also to familiarize myself with the Bambi codebase before coding officially began. To achieve this, I read through the codebase attempting to understand how the different modules interact with one another. Additionally, I read through the Bambi documentation to understand how the different models are implemented, and any additional functionality provided the library. After familarizing myself with the codebase at a high level, I decided to get a jumpstart on the project deliverables for week 1 through 4. Below is a table of the deliverables for the entire project timeline.

|Week|Deliverable|
|---|---|
|1|Review plot_cap() design and relevant Bambi codebase. Discuss grammar of graphics libraries with mentors. Identify any open GitHub issues regarding plot_cap() that would restrict development.|
|2|Implement predictions at the observational level for plot_cap(), and add tests, and documentation.|
|3|Design of how plot_comparisons() and plot_slopes() can re-utilize the plot_cap() code and be incorporated into the Bambi codebase.|
|4|Begin plot_comparisons() implementation|
|5|Deliver working example of plot_comparisons() for a simple Bambi model, and open draft PR.|
|6|Continue plot_comparisons() implementation. Deliver example on a complex model.|
|7|Write tests, examples, and documentation for plot_comparisons(), and open PR.|
|8|Begin plot_slopes() implementation.|
|9|Deliver working example of plot_slopes() for a simple Bambi model, and open draft PR.|
|10|Continue plot_slopes() implementation. Deliver example on a complex model.|
|11|Write tests, examples, and documentation for plot_slopes(), and open PR.|
|12|Review plot_cap(), plot_comparisons(), and plot_slopes() code. Ensure documentation and examples are correct, and tests pass.|
|13|Final submission. This week is a buffer period for code review, unexpected difficulties, and ensuring documentation and added examples are accurate and comprehensive.|

## Progress

Predictions at the observation level for `plot_cap` were implemented in [PR 668](https://github.com/bambinos/bambi/pull/668). By default, `plot_cap` uses the posterior distribution to visualize some mean outcome parameter of a a GLM. However, the posterior predictive distribution can also be plotted by specifying `pps=True` where `pps` stands for _posterior predictive samples_ of the response variable. Upon completion of the PR above, an example showing the functionality of `plot_cap` was added to the Bambi documentation in [PR 670](https://github.com/bambinos/bambi/pull/670). 

Completing these two deliveribles early on in the program allowed me to spend more time on the design of the `plots` sub-package and implementation of `plot_comparisons` (which is ending up to be more complex than initially thought). For the design of the `plots` sub-package, I decided to create five different modules, each with a specific purpose. The modules are as follows:

* `create_data.py` - creates the data called by the functions in the `effects.py` and `comparisons.py` modules.
* `effects.py` - contains the functions (`predictions`, `comparisons`, `slopes`) that are used to create the dataframe that is passed to the plotting functions and or user when called standalone. 
* `utils.py` - contains commonly used functions that are called by multiple modules in the `plots` sub-package.
* `plotting.py` - contains the plotting functions (`plot_predictions`, `plot_comparisons`, `plot_slopes`) that are used to generate the plots for the user.
* `plot_types.py` - determines the plot types (numeric or categorical) for the the `plotting` module.

The modularization of the `plots` sub-package will allow for easier maintenance and testing of the codebase and offers re-usability of code using OOP principles. The modularization of code happened during the initial development stages of the `plot_comparisons` function. 

Currently, `plot_comparisons` only works when a user defines the covariate and its contrast, and the covariates they would like to condition on. For example:

```python
# user provided contrast for `Age` and default grid 
# calculated for the conditional variable `SexCode`
fig, ax = plot_comparison(
    model=titanic_model,
    idata=titanic_idata,
    contrast_predictor={"Age": [50, 70]},
    conditional="SexCode",
)
```

or

```python
# user can also pass a dict into conditional to define the 
# values used for the conditional variables
fig, ax = plot_comparison(
    model=titanic_model,
    idata=titanic_idata,
    contrast_predictor={"PClass": [1, 3]},
    conditional={"Age": [50], "SexCode": [0, 1]}
)
```

Next week, default contrast values will be computed for numeric and categorical conrast predictors. Additionally, default values for both numeric and categorical conditinoal variables will be added. This will allow the user to call `plot_comparisons` without having to specify contrast and conditional variable values.